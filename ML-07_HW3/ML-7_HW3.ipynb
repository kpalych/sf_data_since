{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/_train_sem09 (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseLine для модели LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_base = linear_model.LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на тестовом выборке 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72       344\n",
      "           1       0.76      0.79      0.78       407\n",
      "\n",
      "    accuracy                           0.75       751\n",
      "   macro avg       0.75      0.75      0.75       751\n",
      "weighted avg       0.75      0.75      0.75       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = log_reg_base.predict(X_test)\n",
    "print('F1-score на тестовом выборке {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый показатель F1-score: 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV для модели LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.64 s\n",
      "Wall time: 9min 20s\n",
      "F1-score на тестовом наборе: 0.78\n",
      "Наилучшие значения гиперпараметров: {'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2', 'none'],\n",
    "        'solver': ['lbfgs', 'saga']\n",
    "    }\n",
    "]\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=random_state\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")  \n",
    "%time grid_search.fit(X_train, y_train) \n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('F1-score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print('Наилучшие значения гиперпараметров: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшения целевой метрики добиться не удалось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV для модели LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.44 s\n",
      "Wall time: 26min 35s\n",
      "F1-score на тестовом наборе: 0.78\n",
      "Наилучшие значения гиперпараметров: {'solver': 'sag', 'penalty': 'l2', 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "param_grid_rnd = {\n",
    "    'penalty': ['l2', 'none'] ,\n",
    "    'solver': ['lbfgs', 'sag'],\n",
    "    'C': list(np.linspace(0.01, 1, 10, dtype=float))\n",
    "},\n",
    "            \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=random_state\n",
    "    ), \n",
    "    param_distributions=param_grid_rnd, \n",
    "    cv=5, \n",
    "    n_iter=10, \n",
    "    n_jobs=-1\n",
    ")  \n",
    "\n",
    "%time random_search.fit(X_train, y_train)\n",
    "y_test_pred = random_search.predict(X_test)\n",
    "print('F1-score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print('Наилучшие значения гиперпараметров: {}'.format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За счет того, что метод работает быстрее чем GridSearchCV можно задать большее широкое пространство перебираемых параметров.\n",
    "\n",
    "Однако данный метод, даже несмотря более широкое пространство параметров улучшение относительно BaseLine, не дал улучшения целевой метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt для модели LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Hyperopt : 0.2.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space = {\n",
    "    'penalty': hp.choice('penalty', ['l2', 'none']),\n",
    "    'solver' : hp.choice('solver', ['newton-cg', 'sag', 'saga', 'lbfgs']),\n",
    "    'C' : hp.uniform('C', 0.01, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {\n",
    "        'penalty': params['penalty'], \n",
    "        'solver': params['solver'], \n",
    "        'C': float(params['C'])\n",
    "    }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(\n",
    "        **params,\n",
    "        max_iter=1000,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # обучаем модель\n",
    "    # используем cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [42:30<00:00, 127.53s/trial, best loss: -0.7902171664645037]\n",
      "Наилучшие значения гиперпараметров {'C': 0.05084775379720359, 'penalty': 0, 'solver': 0}\n",
      "CPU times: total: 1.64 s\n",
      "Wall time: 42min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(\n",
    "    hyperopt_lr,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(random_state)\n",
    ")\n",
    "print('Наилучшие значения гиперпараметров {}'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.05084775379720359, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "best_params = hyperopt.space_eval(space, best)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на тестовом выборке 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.73       344\n",
      "           1       0.76      0.82      0.79       407\n",
      "\n",
      "    accuracy                           0.76       751\n",
      "   macro avg       0.76      0.76      0.76       751\n",
      "weighted avg       0.76      0.76      0.76       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем F1 метрику для тестовой выборки\n",
    "\n",
    "model_lr = linear_model.LogisticRegression(\n",
    "    penalty=best_params['penalty'],\n",
    "    solver=best_params['solver'],\n",
    "    C=float(best_params['C']),\n",
    "    max_iter=1000,\n",
    "    random_state=random_state\n",
    ")\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model_lr.predict(X_test)\n",
    "print('F1-score на тестовом выборке {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод подбора гиперпараметров позволил улучшить целевую метрику с 0.78 до 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna для модели LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Optuna: 3.0.3\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "print(\"Версия Optuna: {}\".format(optuna.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_lr(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', 'none'])\n",
    "    solver = trial.suggest_categorical('solver', ['newton-cg', 'sag', 'saga', 'lbfgs'])\n",
    "    C = trial.suggest_float('C', 0.01, 1)\n",
    "\n",
    "    # создаем модель\n",
    "    model = linear_model.LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        C=C,\n",
    "        max_iter=1000,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # обучаем модель\n",
    "    # используем cross validation с количеством фолдов == 5\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-19 08:09:23,543]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:12:17,913]\u001b[0m Trial 0 finished with value: 0.7597800660015992 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.2778164748439764}. Best is trial 0 with value: 0.7597800660015992.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:17:30,324]\u001b[0m Trial 1 finished with value: 0.7626510635585347 and parameters: {'penalty': 'none', 'solver': 'saga', 'C': 0.17376873090670436}. Best is trial 1 with value: 0.7626510635585347.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:21:23,706]\u001b[0m Trial 2 finished with value: 0.7597800660015992 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.9476564950457328}. Best is trial 1 with value: 0.7626510635585347.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:21:36,557]\u001b[0m Trial 3 finished with value: 0.7754927645452376 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.9629668753862248}. Best is trial 3 with value: 0.7754927645452376.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:24:01,063]\u001b[0m Trial 4 finished with value: 0.7780173758251074 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.6828912592288647}. Best is trial 4 with value: 0.7780173758251074.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:26:25,720]\u001b[0m Trial 5 finished with value: 0.7777773494485827 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.691084585547781}. Best is trial 4 with value: 0.7780173758251074.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:26:32,898]\u001b[0m Trial 6 finished with value: 0.7790329475724629 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.34485297250479907}. Best is trial 6 with value: 0.7790329475724629.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:32:34,880]\u001b[0m Trial 7 finished with value: 0.7626510635585347 and parameters: {'penalty': 'none', 'solver': 'saga', 'C': 0.4354945400784564}. Best is trial 6 with value: 0.7790329475724629.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:34:14,233]\u001b[0m Trial 8 finished with value: 0.7857532717525056 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.10087610300556314}. Best is trial 8 with value: 0.7857532717525056.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:34:41,176]\u001b[0m Trial 9 finished with value: 0.7192422379991589 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.4992690647169819}. Best is trial 8 with value: 0.7857532717525056.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:34:47,483]\u001b[0m Trial 10 finished with value: 0.7941922511507042 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01965899746649856}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:34:54,646]\u001b[0m Trial 11 finished with value: 0.792390935152632 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.029135760247303844}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:35:01,298]\u001b[0m Trial 12 finished with value: 0.792757323742938 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.015288978718230822}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:35:11,196]\u001b[0m Trial 13 finished with value: 0.7813350043452633 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.1901855013934814}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:35:18,671]\u001b[0m Trial 14 finished with value: 0.7894904900730986 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01237894284564585}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:35:35,841]\u001b[0m Trial 15 finished with value: 0.7783476436409609 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.2647767320832795}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:35:52,997]\u001b[0m Trial 16 finished with value: 0.7786047475607094 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.6701918781930684}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:36:05,438]\u001b[0m Trial 17 finished with value: 0.7839774538418534 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.13696037234727315}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:36:22,485]\u001b[0m Trial 18 finished with value: 0.7794209339728309 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.3698839443555366}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 08:36:36,239]\u001b[0m Trial 19 finished with value: 0.7770846991155265 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.8214522987815722}. Best is trial 10 with value: 0.7941922511507042.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.7 s\n",
      "Wall time: 27min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# необходимо максимизировать метрику => direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "study.optimize(optuna_lr, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01965899746649856}\n",
      "F1-score на обучающем наборе: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Наилучшие значения гиперпараметров {}'.format(study.best_params))\n",
    "print('F1-score на обучающем наборе: {:.2f}'.format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на тестовом выборке 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       344\n",
      "           1       0.75      0.81      0.78       407\n",
      "\n",
      "    accuracy                           0.75       751\n",
      "   macro avg       0.75      0.75      0.75       751\n",
      "weighted avg       0.75      0.75      0.75       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model_lr = linear_model.LogisticRegression(\n",
    "    **study.best_params,\n",
    "    max_iter=1000,\n",
    "    random_state=random_state\n",
    ")\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model_lr.predict(X_test)\n",
    "print('F1-score на тестовом выборке {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На теством наборе данный метод улучшения целевой метрики не дал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseLine для модели RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, min_samples_leaf=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, min_samples_leaf=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_leaf=5, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на тестовом наборе: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       344\n",
      "           1       0.79      0.81      0.80       407\n",
      "\n",
      "    accuracy                           0.78       751\n",
      "   macro avg       0.78      0.78      0.78       751\n",
      "weighted avg       0.78      0.78      0.78       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model_rf.predict(X_test)\n",
    "print('F1-score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение целевой метрики, которую мы пытаемся улучшить подбором гиперпараметров, для модели RandomForestClassifier - 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV для модели RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.64 s\n",
      "Wall time: 5min 55s\n",
      "F1-score на тестовом наборе: 0.80\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 30, 'min_samples_leaf': 2, 'n_estimators': 275}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       344\n",
      "           1       0.79      0.81      0.80       407\n",
      "\n",
      "    accuracy                           0.78       751\n",
      "   macro avg       0.78      0.78      0.78       751\n",
      "weighted avg       0.78      0.78      0.78       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': list(range(100, 300, 25)),\n",
    "    'max_depth': list(np.linspace(10, 50, 5, dtype=int)),\n",
    "    'min_samples_leaf': list(np.linspace(2, 8, 1, dtype=int))\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=random_state), \n",
    "    param_grid=param_grid,\n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time grid_search.fit(X_train, y_train) \n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('F1-score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print('Наилучшие значения гиперпараметров: {}'.format(grid_search.best_params_))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод не позволил улучшить целевую метрику"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV для модели RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.08 s\n",
      "Wall time: 1min 2s\n",
      "F1-score на тестовом наборе: 0.80\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 125, 'min_samples_leaf': 2, 'max_depth': 40}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       344\n",
      "           1       0.79      0.81      0.80       407\n",
      "\n",
      "    accuracy                           0.78       751\n",
      "   macro avg       0.78      0.78      0.78       751\n",
      "weighted avg       0.78      0.78      0.78       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': list(range(100, 300, 25)),\n",
    "    'max_depth': list(np.linspace(10, 50, 5, dtype=int)),\n",
    "    'min_samples_leaf': list(np.linspace(2, 8, 1, dtype=int))\n",
    "}\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=random_state), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5,\n",
    "    n_iter=10, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time random_search_forest.fit(X_train, y_train) \n",
    "y_test_pred = random_search_forest.predict(X_test)\n",
    "print('F1-score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print('Наилучшие значения гиперпараметров: {}'.format(random_search_forest.best_params_))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод не позволил улучшить целевую метрику"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt для модели RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 300, 25),\n",
    "    'max_depth' : hp.quniform('max_depth', 10, 50, 5),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 8, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']), \n",
    "        'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "    }\n",
    "  \n",
    "    model = ensemble.RandomForestClassifier(\n",
    "        **params, \n",
    "        random_state=random_state\n",
    "    )\n",
    "   \n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:34<00:00,  7.74s/trial, best loss: -0.8182768218494241]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 35.0, 'min_samples_leaf': 2.0, 'n_estimators': 125.0}\n",
      "CPU times: total: 1.28 s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(\n",
    "    hyperopt_rf,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(random_state)\n",
    ")\n",
    "\n",
    "print('Наилучшие значения гиперпараметров {}'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на тестовом наборе: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       344\n",
      "           1       0.79      0.81      0.80       407\n",
      "\n",
      "    accuracy                           0.78       751\n",
      "   macro avg       0.78      0.78      0.78       751\n",
      "weighted avg       0.78      0.78      0.78       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('F1-score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод не позволил улучшить целевую метрику"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna для модели RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, 25)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 50, 5)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 8, 1)\n",
    "\n",
    "    # создаем модель\n",
    "    model = ensemble.RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # обучаем модель\n",
    "    # используем cross validation с количеством фолдов == 5\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-19 09:38:30,476]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:38:33,823]\u001b[0m Trial 0 finished with value: 0.8014827557840256 and parameters: {'n_estimators': 100, 'max_depth': 45, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8014827557840256.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:38:44,752]\u001b[0m Trial 1 finished with value: 0.8055269772084582 and parameters: {'n_estimators': 300, 'max_depth': 35, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.8055269772084582.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:38:57,998]\u001b[0m Trial 2 finished with value: 0.8149858995071237 and parameters: {'n_estimators': 200, 'max_depth': 45, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8149858995071237.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:39:15,356]\u001b[0m Trial 3 finished with value: 0.8121623022289184 and parameters: {'n_estimators': 250, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8149858995071237.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:39:31,363]\u001b[0m Trial 4 finished with value: 0.815949454065797 and parameters: {'n_estimators': 225, 'max_depth': 50, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.815949454065797.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:39:39,931]\u001b[0m Trial 5 finished with value: 0.8082632868515267 and parameters: {'n_estimators': 175, 'max_depth': 35, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.815949454065797.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:39:46,714]\u001b[0m Trial 6 finished with value: 0.8073309424847576 and parameters: {'n_estimators': 125, 'max_depth': 20, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.815949454065797.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:39:57,180]\u001b[0m Trial 7 finished with value: 0.8038728601891467 and parameters: {'n_estimators': 225, 'max_depth': 15, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.815949454065797.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:40:03,237]\u001b[0m Trial 8 finished with value: 0.8029320972689395 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.815949454065797.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:40:25,502]\u001b[0m Trial 9 finished with value: 0.8098612121499279 and parameters: {'n_estimators': 275, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.815949454065797.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:40:36,188]\u001b[0m Trial 10 finished with value: 0.8172282840191762 and parameters: {'n_estimators': 175, 'max_depth': 50, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8172282840191762.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:40:44,740]\u001b[0m Trial 11 finished with value: 0.8159438280162232 and parameters: {'n_estimators': 150, 'max_depth': 50, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8172282840191762.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:40:55,823]\u001b[0m Trial 12 finished with value: 0.8145652135159441 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.8172282840191762.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:41:08,823]\u001b[0m Trial 13 finished with value: 0.8136981179632903 and parameters: {'n_estimators': 225, 'max_depth': 40, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.8172282840191762.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:41:19,626]\u001b[0m Trial 14 finished with value: 0.8109915723507793 and parameters: {'n_estimators': 175, 'max_depth': 50, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.8172282840191762.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:41:38,881]\u001b[0m Trial 15 finished with value: 0.8183905551700702 and parameters: {'n_estimators': 250, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 15 with value: 0.8183905551700702.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:41:55,366]\u001b[0m Trial 16 finished with value: 0.8126762051262075 and parameters: {'n_estimators': 275, 'max_depth': 40, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8183905551700702.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:42:06,076]\u001b[0m Trial 17 finished with value: 0.8109512538885086 and parameters: {'n_estimators': 150, 'max_depth': 40, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8183905551700702.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:42:22,893]\u001b[0m Trial 18 finished with value: 0.8183905551700702 and parameters: {'n_estimators': 250, 'max_depth': 45, 'min_samples_leaf': 2}. Best is trial 15 with value: 0.8183905551700702.\u001b[0m\n",
      "\u001b[32m[I 2022-10-19 09:42:38,375]\u001b[0m Trial 19 finished with value: 0.8145618748544223 and parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_leaf': 6}. Best is trial 15 with value: 0.8183905551700702.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.67 s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# необходимо максимизировать метрику => direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score на тестовом выборке 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       344\n",
      "           1       0.80      0.81      0.80       407\n",
      "\n",
      "    accuracy                           0.78       751\n",
      "   macro avg       0.78      0.78      0.78       751\n",
      "weighted avg       0.78      0.78      0.78       751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model_rf = ensemble.RandomForestClassifier(\n",
    "    **study.best_params,\n",
    "    random_state=random_state\n",
    ")\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model_rf.predict(X_test)\n",
    "print('F1-score на тестовом выборке {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод не позволил улучшить целевую метрику"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель RandomForestClassifie изначально показала более высокий показатель целевой метрики относительно модели LogisticRegression.\n",
    "\n",
    "Путем подбора гиперпарамотров для модели LogisticRegression удалось улучшить показатель целевой метрики (с 0.78 до 0.79) при помощи метода Hyperopt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47c0b164d4c80d354a5d99eb92b309a98cf0f6fa9ee293d69a50603f87ba7f0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
